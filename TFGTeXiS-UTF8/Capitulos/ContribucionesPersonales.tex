\chapter*{Contribuciones Personales}
\label{cap:contribucionesPersonales}
\addcontentsline{toc}{chapter}{Contribuciones Personales}
\section*{Estudiante 1: Sergio Llorente Hernando}
Lo primero de todo fue reflexionar sobre los objetivos del proyecto, de manera que realicé una investigación sobre la terapia ocupacional, los libros de vida y las distintas inteligencias artificiales, con el objetivo de saber qué tecnología debemos utilizar para satisfacer las necesidades de los usuarios.
Desde un primer momento hice una labor de búsqueda y prueba de diferentes modelos de inteligencia artificial generativa de imágenes. En primer lugar, la prueba era con servidores especializados y más adelante, hice una descarga de los modelos que generaban imágenes de calidad, con el objetivo de comprobar cuáles de los modelos podrían funcionar mejor y otorgar unos resultados satisfactorios.\\

El siguiente paso en el que me centré fue en conseguir hacer funcionar la inteligencia artificial generativa en local. Para ello, en primer lugar opté por probar los modelos en anaconda, lo cual no era una interfaz cómoda para el usuario y la generación de imágenes era lenta. A continuación empecé a trabajar con SDGUI, una aplicación con la que podía testar cualquier tipo de modelo, ya sea entrenado o no, y además de eso, ajustar todos los parámetros necesarios. Con esta aplicación sí que se generaban bien las imágenes. Esto sirvió para diseñar nuestro propio programa que incluyera el modelo generativo. \\

Para crear la aplicación, primero opté por crear un script de Python. Esto dio buenos resultados, porque mostraba la imagen al igual que en el programa de referencia, pero la interfaz no era buena para el usuario, y además haciendo pruebas en cualquier otro ordenador no obtuve resultados. Este hecho hizo que creara un entorno virtual para saber las dependencias que son necesarias para que funcione el modelo, y por otro lado, dividir el back y el front, con el objetivo de hacer más atractiva la aplicación mediante html, que es un lenguaje con el que ya estaba más familiarizado. Esto dio un mejor resultado, a pesar de no conseguir que el modelo de inteligencia artificial fuese uno entrenado por nosotros mismos.\\

La siguiente fase del trabajo, fue la del entrenamiento de los modelos, con el objetivo de tener la capacidad de personalizar la inteligencia artificial a petición de cualquier usuario. Fue un trabajo muy complejo en el que hice muchísimas pruebas con diferentes vías, con el objetivo de obtener los mejores resultados posibles. Fueron múltiples pruebas debido a que, para ofrecer al usuario la experiencia óptima, necesitamos conocer cuántas imágenes y cuántos pasos de aprendizaje se requieren. Tras la realización de estas pruebas se concluyó que la estrategia más óptima era utilizar un conjunto de 10 imágenes y 2400 pasos de entrenamiento. No obstante, hicieron falta múltiples entrenamientos erróneos o parcialmente correctos para conocer este hecho.\\
 
La siguiente fase fue realizar más entrenamientos con diferentes elementos y analizar los resultados. Además, aquí opté por examinar si un resultado de un entrenamiento podía servir de base para un próximo. La respuesta fue afirmativa y eso me llevó a añadir múltiples capas a un mismo modelo, lo cual podría ayudar a un usuario a tener un solo modelo personalizado que incluya todos los elementos que desee. 


\section*{Estudiante 2: Isabella Romano Ramos}
Lo primero que realicé fue la introducción del tema de estudio sobre el trabajo después de la primera sesión de reunión con el tutor en la que quedaron claros los aspectos generales que se iban a abordar, los objetivos principales y las tecnologías que se iban a utilizar. \\

Una vez definido esto, empezó la fase de investigación sobre los temas principales que abordaban el proyecto: el Alzheimer y la Inteligencia Artificial. Me embarqué en un proceso de recopilación de información para entender lo que ocurre en el cerebro que hace que se deteriore la memoria y que cause esta enfermedad que afecta a millones de personas, y así poder reflejarlo en la memoria. En cuanto a la IA, era un concepto totalmente nuevo para mí ya que no había visto nada sobre este campo en ninguna asignatura de la carrera. Por lo que opté empezar a entenderla por el principio, desde un concepto tan simple como el perceptrón, hasta examinar las redes neuronales, pasando por todos los tipos de modelos fundamentales qué existen y saber diferenciar la función de cada uno. Por ende, me encargué de buscar la bibliografía que hablaba de la IA, más en concreto sobre el Deep Learning y las redes neuronales. De esta manera, lo pude redactar de manera que se entendiera lo mejor posible en el Capítulo 2 Estado de la cuestión. \\

Como se ha podido ver a lo largo de todo el proyecto, nos hemos centrado en el campo concreto de la Inteligencia Artificial generativa de imágenes y lo que hicé fue investigar las diferentes alternativas de modelos ya implementados que pudiéramos utilizar para el entrenamiento de personas y la integración en nuestra futura aplicación. Tras examinar profundamente las prestaciones y disponibilidad de cada uno, entre los tres candidatos finales, que se trataban de Midjourney, Dall-e y Stable Diffusion, se eligió usar el último por las limitaciones que nos mostraban los otros dos modelos. Una vez elegido, hice un análisis profundo de cómo está implementado el modelo de difusión estable que utiliza la herramienta y lo redacté extensamente en el Capítulo 2 Estado de la cuestión. Además, durante el proceso surgieron conceptos interesantes en relación con Stable Diffusion, como LORA y Dreambooth e incluso, consideré importante añadir la importancia de la ingeniería del prompt para la creación de imágenes a partir de texto. \\

Cuando pude comprender los conceptos teóricos que explicaban el funcionamiento de Stable Diffusion, se pasó a la parte práctica, es decir, a pensar en la estructura y usos de la aplicación que se iba a desarrollar como apoyo al modelo de IA generativa seleccionado. Finalmente, caímos en la cuenta de que las prestaciones que ofrecen mis dos equipos, tanto mi portatil como el ordenador de sobremesa, no cumplen los requisitos mínimos para poder ejecutar la aplicación en local ni realizar las pruebas necesarias sobre la generación de imágenes, al no contar con GPU en el portátil y no ser lo suficientemente potente la GPU en el ordenador de sobremesa. Es decir, era inviable que se pudieran generar imágenes en mis equipos.\\

Por ello, solo me podía limitar a entrenar el modelo que seleccionamos a través de la herramienta de Google Colab. Fue entonces cuando busqué en Hugging Face el modelo de Stable Diffusion más adecuado, que resultó ser el 1.5, y fui probando el número de pasos y de imágenes que producían los mejores resultados. 
Además, me encargué de organizar y estructurar el contenido de la memoria en la herramienta de Latex, utilizada para generar este mismo documento. \\

Para la aplicación, al no poder hacer pruebas en la generación de imágenes, me encargué de buscar e investigar sobre las mejores opciones para realizar el front en HTML. En el camino, pude dar con un software llamado Bootstrap que es muy eficiente y útil para facilitar el proceso del diseño del front, de forma fácil y sencilla.\\
